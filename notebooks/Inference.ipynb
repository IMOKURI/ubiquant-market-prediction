{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "def in_kaggle():\n",
    "    return \"kaggle_web_client\" in sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### INSERT SOURCE CODE HERE FOR SUBMISSION #####\n",
    "\n",
    "if in_kaggle():\n",
    "    sys.path.append(\"../input/nptyping\")\n",
    "    sys.path.append(\"../input/typish\")\n",
    "else:\n",
    "    sys.path.append(\"..\")\n",
    "    sys.path.append(\"../../inputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if in_kaggle():\n",
    "    # https://www.kaggle.com/speeddemon/install-hydra-offline-from-dataset\n",
    "\n",
    "    !cp -r /kaggle/input/hydracore105 /kaggle/working\n",
    "    !mv /kaggle/working/hydracore105/antlr4-python3-runtime-4.8.tar.gz.tmp /kaggle/working/hydracore105/antlr4-python3-runtime-4.8.tar.gz\n",
    "    !ls /kaggle/working/hydracore105\n",
    "\n",
    "    !pip install -qq /kaggle/working/hydracore105/* --ignore-installed PyYAML\n",
    "    \n",
    "    sys.path.append(\"../input/omegaconf/omegaconf-master\")\n",
    "    omega_conf_path = \"config/main.yaml\"\n",
    "    \n",
    "else:\n",
    "    omega_conf_path = \"../config/main.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "c = OmegaConf.load(omega_conf_path)\n",
    "\n",
    "c.settings.debug = False\n",
    "c.wandb.enabled = False\n",
    "\n",
    "if in_kaggle():\n",
    "    c.settings.gpus = \"0\"\n",
    "\n",
    "    c.settings.dirs.working = \".\"\n",
    "    c.settings.dirs.input = \"../input/ubiquant-market-prediction/\"\n",
    "    c.settings.dirs.feature = \"../input/ubiquant-parquet/\"\n",
    "\n",
    "    pretraind_dir = \"../input/ump-models\"\n",
    "\n",
    "else:\n",
    "    c.settings.dirs.working = \"..\"\n",
    "    c.settings.dirs.input = \"../../inputs/\"\n",
    "\n",
    "    pretraind_dir = \"../../datasets/trainings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = f\"\"\"\n",
    "- dir: {pretraind_dir}/2022-02-04_23-43-25/fold0/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-02-04_23-43-27/fold1/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-02-04_23-43-29/fold2/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-02-04_23-43-31/fold3/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-02-04_23-43-33/fold4/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-02-05_08-05-00/fold5/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-02-05_08-05-02/fold6/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-02-05_08-05-04/fold7/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-02-05_08-05-06/fold8/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-02-05_08-05-08/fold9/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-02-05_20-09-55/fold10/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-02-05_20-09-57/fold11/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-02-05_20-09-59/fold12/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-02-05_20-10-01/fold13/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-02-05_20-10-04/fold14/\n",
    "  model: ump_1\n",
    "\"\"\"\n",
    "\n",
    "_pretrained = f\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "c.params.pretrained = OmegaConf.create(pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaults:\n",
      "- _self_\n",
      "hydra:\n",
      "  run:\n",
      "    dir: ../outputs/${now:%Y-%m-%d_%H-%M-%S}\n",
      "  job_logging:\n",
      "    formatters:\n",
      "      simple:\n",
      "        format: '%(asctime)s [%(levelname)s][%(module)s] %(message)s'\n",
      "wandb:\n",
      "  enabled: false\n",
      "  entity: imokuri\n",
      "  project: ump\n",
      "  dir: ${hydra:runtime.cwd}/../cache\n",
      "  group: default\n",
      "settings:\n",
      "  print_freq: 100\n",
      "  gpus: 6,7\n",
      "  dirs:\n",
      "    working: ..\n",
      "    input: ../../inputs/\n",
      "    feature: ${settings.dirs.input}features/\n",
      "    preprocess: ${settings.dirs.input}preprocess/\n",
      "  inputs:\n",
      "  - train.csv\n",
      "  - example_test.csv\n",
      "  - example_sample_submission.csv\n",
      "  debug: false\n",
      "  n_debug_data: 100000\n",
      "  amp: true\n",
      "  multi_gpu: true\n",
      "params:\n",
      "  seed: 440\n",
      "  n_class: 1\n",
      "  preprocess: false\n",
      "  n_fold: 5\n",
      "  skip_training: false\n",
      "  epoch: 20\n",
      "  es_patience: 0\n",
      "  batch_size: 640\n",
      "  gradient_acc_step: 1\n",
      "  max_grad_norm: 1000\n",
      "  fold: simple_cpcv\n",
      "  group_name: investment_id\n",
      "  time_name: time_id\n",
      "  label_name: target\n",
      "  use_feature: true\n",
      "  feature_set:\n",
      "  - f000\n",
      "  dataset: ump_1\n",
      "  model: ump_1\n",
      "  pretrained:\n",
      "  - dir: ../../datasets/trainings/2022-02-04_23-43-25/fold0/\n",
      "    model: ump_1\n",
      "  - dir: ../../datasets/trainings/2022-02-04_23-43-27/fold1/\n",
      "    model: ump_1\n",
      "  - dir: ../../datasets/trainings/2022-02-04_23-43-29/fold2/\n",
      "    model: ump_1\n",
      "  - dir: ../../datasets/trainings/2022-02-04_23-43-31/fold3/\n",
      "    model: ump_1\n",
      "  - dir: ../../datasets/trainings/2022-02-04_23-43-33/fold4/\n",
      "    model: ump_1\n",
      "  - dir: ../../datasets/trainings/2022-02-05_08-05-00/fold5/\n",
      "    model: ump_1\n",
      "  - dir: ../../datasets/trainings/2022-02-05_08-05-02/fold6/\n",
      "    model: ump_1\n",
      "  - dir: ../../datasets/trainings/2022-02-05_08-05-04/fold7/\n",
      "    model: ump_1\n",
      "  - dir: ../../datasets/trainings/2022-02-05_08-05-06/fold8/\n",
      "    model: ump_1\n",
      "  - dir: ../../datasets/trainings/2022-02-05_08-05-08/fold9/\n",
      "    model: ump_1\n",
      "  - dir: ../../datasets/trainings/2022-02-05_20-09-55/fold10/\n",
      "    model: ump_1\n",
      "  - dir: ../../datasets/trainings/2022-02-05_20-09-57/fold11/\n",
      "    model: ump_1\n",
      "  - dir: ../../datasets/trainings/2022-02-05_20-09-59/fold12/\n",
      "    model: ump_1\n",
      "  - dir: ../../datasets/trainings/2022-02-05_20-10-01/fold13/\n",
      "    model: ump_1\n",
      "  - dir: ../../datasets/trainings/2022-02-05_20-10-04/fold14/\n",
      "    model: ump_1\n",
      "  criterion: RMSELoss\n",
      "  optimizer: Adam\n",
      "  scheduler: CosineAnnealingWarmupRestarts\n",
      "  lr: 0.001\n",
      "  min_lr: 1.0e-06\n",
      "  weight_decay: 1.0e-05\n",
      "  label_smoothing: 1.0e-06\n",
      "  scoring: pearson\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(OmegaConf.to_yaml(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import traceback\n",
    "\n",
    "import numpy as np\n",
    "import src.utils as utils\n",
    "import ubiquant\n",
    "from src.feature_store import Store\n",
    "from src.features.base import get_feature\n",
    "from src.make_feature import make_feature\n",
    "from src.make_model import load_model\n",
    "from src.run_loop import inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.fix_seed(c.params.seed)\n",
    "utils.debug_settings(c)\n",
    "device = utils.gpu_settings(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature set: ['f000']\n"
     ]
    }
   ],
   "source": [
    "feature_set = [\"f000\"]\n",
    "\n",
    "feature_set = list(sorted(list(set(feature_set))))\n",
    "print(f\"feature set: {feature_set}\")\n",
    "\n",
    "feature_func = [get_feature(f) for f in feature_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = Store.empty()\n",
    "# store = Store.train(c)  # Your notebook tried to allocate more memory than is available.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = load_model(c, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ubiquant.make_env()  # initialize the environment\n",
    "iter_test = env.iter_test()  # an iterator which loops over the test set and sample submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [f\"f_{n}\" for n in range(300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n"
     ]
    }
   ],
   "source": [
    "for test_df, sample_prediction_df in iter_test:\n",
    "    try:\n",
    "        gc.collect()\n",
    "\n",
    "        if c.params.use_feature:\n",
    "            for row in test_df.values:\n",
    "                store.append(row)\n",
    "\n",
    "            pred_df = make_feature(\n",
    "                test_df,\n",
    "                store,\n",
    "                feature_set,\n",
    "                load_from_store=False,\n",
    "                save_to_store=False,\n",
    "                debug=c.settings.debug,\n",
    "            )\n",
    "            df = inference(c, pred_df, device, models)\n",
    "\n",
    "            # else:\n",
    "            _df = inference(c, test_df, device, models)\n",
    "\n",
    "        # print(\"=\" * 80)\n",
    "        # diff_df = test_df[feature_cols].astype(\"float32\").compare(pred_df[feature_cols])\n",
    "        # print(diff_df)\n",
    "        # print(test_df.info())\n",
    "        # print(pred_df.info())\n",
    "\n",
    "        assert len(test_df[\"investment_id\"].unique()) == len(test_df[\"investment_id\"]), \"investment_id is not unique.\"\n",
    "\n",
    "        assert len(test_df) == len(pred_df), \"test_df and pred_df do not same size.\"\n",
    "\n",
    "        assert test_df[\"f_0\"].astype(\"float32\").equals(pred_df[\"f_0\"]), \"test_df and pred_df do not same feature.\"\n",
    "\n",
    "        # assert (\n",
    "        #     test_df[feature_cols].astype(\"float32\").equals(pred_df[feature_cols])\n",
    "        # ), \"Default features do not match between test_df and pred_df.\"\n",
    "\n",
    "        # assert df[\"target\"].equals(_df[\"target\"]), \"Predictions do not match between test_df and pred_df.\"\n",
    "\n",
    "        sample_prediction_df[\"target\"] = _df[\"target\"]  # make your predictions here\n",
    "\n",
    "        # DEBUG\n",
    "        # sample_prediction_df.fillna({\"target\": 0}, inplace=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(traceback.format_exc())\n",
    "        raise\n",
    "\n",
    "    env.predict(sample_prediction_df)  # register your predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37-all-in-one",
   "language": "python",
   "name": "py37-all-in-one"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
