{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "def in_kaggle():\n",
    "    return \"kaggle_web_client\" in sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### INSERT SOURCE CODE HERE FOR SUBMISSION #####\n",
    "\n",
    "if not in_kaggle():\n",
    "    sys.path.append(\"..\")\n",
    "    sys.path.append(\"../../inputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if in_kaggle():\n",
    "    # https://www.kaggle.com/speeddemon/install-hydra-offline-from-dataset\n",
    "\n",
    "    !cp -r /kaggle/input/hydracore105 /kaggle/working\n",
    "    !mv /kaggle/working/hydracore105/antlr4-python3-runtime-4.8.tar.gz.tmp /kaggle/working/hydracore105/antlr4-python3-runtime-4.8.tar.gz\n",
    "    !ls /kaggle/working/hydracore105\n",
    "\n",
    "    !pip install -qq /kaggle/working/hydracore105/* --ignore-installed PyYAML\n",
    "    \n",
    "    sys.path.append(\"../input/omegaconf/omegaconf-master\")\n",
    "    omega_conf_path = \"config/main.yaml\"\n",
    "    \n",
    "else:\n",
    "    omega_conf_path = \"../config/main.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaults:\n",
      "- _self_\n",
      "hydra:\n",
      "  run:\n",
      "    dir: ../outputs/${now:%Y-%m-%d_%H-%M-%S}\n",
      "  job_logging:\n",
      "    formatters:\n",
      "      simple:\n",
      "        format: '%(asctime)s [%(levelname)s][%(module)s] %(message)s'\n",
      "wandb:\n",
      "  enabled: false\n",
      "  entity: imokuri\n",
      "  project: ump\n",
      "  dir: ${hydra:runtime.cwd}/../cache\n",
      "  group: default\n",
      "settings:\n",
      "  print_freq: 100\n",
      "  gpus: 6,7\n",
      "  dirs:\n",
      "    working: ..\n",
      "    input: ../../inputs/\n",
      "  inputs:\n",
      "  - train.csv\n",
      "  - example_test.csv\n",
      "  - example_sample_submission.csv\n",
      "  debug: false\n",
      "  n_debug_data: 100000\n",
      "  amp: true\n",
      "  multi_gpu: true\n",
      "params:\n",
      "  seed: 440\n",
      "  n_class: 1\n",
      "  n_fold: 5\n",
      "  skip_training: false\n",
      "  epoch: 20\n",
      "  es_patience: 0\n",
      "  batch_size: 640\n",
      "  gradient_acc_step: 1\n",
      "  max_grad_norm: 1000\n",
      "  fold: simple_cpcv\n",
      "  group_name: investment_id\n",
      "  time_name: time_id\n",
      "  label_name: target\n",
      "  feature_set:\n",
      "  - f000\n",
      "  dataset: ump_1\n",
      "  model: ump_1dcnn\n",
      "  pretrained:\n",
      "  - dir: ../../datasets/trainings/2022-02-01_20-23-49/fold0/\n",
      "    model: ump_1\n",
      "  - dir: ../../datasets/trainings/2022-02-01_20-23-51/fold1/\n",
      "    model: ump_1\n",
      "  - dir: ../../datasets/trainings/2022-02-01_20-23-53/fold2/\n",
      "    model: ump_1\n",
      "  - dir: ../../datasets/trainings/2022-02-01_20-23-55/fold3/\n",
      "    model: ump_1\n",
      "  - dir: ../../datasets/trainings/2022-02-01_20-23-58/fold4/\n",
      "    model: ump_1\n",
      "  - dir: ../../datasets/trainings/2022-02-01_20-24-00/fold5/\n",
      "    model: ump_1\n",
      "  - dir: ../../datasets/trainings/2022-02-01_20-24-02/fold6/\n",
      "    model: ump_1\n",
      "  - dir: ../../datasets/trainings/2022-02-01_20-24-04/fold7/\n",
      "    model: ump_1\n",
      "  - dir: ../../datasets/trainings/2022-02-02_00-43-02/fold8/\n",
      "    model: ump_1\n",
      "  - dir: ../../datasets/trainings/2022-02-02_00-43-04/fold9/\n",
      "    model: ump_1\n",
      "  - dir: ../../datasets/trainings/2022-02-02_00-43-06/fold10/\n",
      "    model: ump_1\n",
      "  - dir: ../../datasets/trainings/2022-02-02_00-43-08/fold11/\n",
      "    model: ump_1\n",
      "  - dir: ../../datasets/trainings/2022-02-02_00-43-11/fold12/\n",
      "    model: ump_1\n",
      "  - dir: ../../datasets/trainings/2022-02-02_00-43-13/fold13/\n",
      "    model: ump_1\n",
      "  - dir: ../../datasets/trainings/2022-02-02_00-43-15/fold14/\n",
      "    model: ump_1\n",
      "  criterion: RMSELoss\n",
      "  optimizer: Adam\n",
      "  scheduler: CosineAnnealingWarmupRestarts\n",
      "  lr: 0.001\n",
      "  min_lr: 1.0e-06\n",
      "  weight_decay: 1.0e-05\n",
      "  label_smoothing: 1.0e-06\n",
      "  scoring: pearson\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "c = OmegaConf.load(omega_conf_path)\n",
    "\n",
    "c.settings.debug = False\n",
    "c.wandb.enabled = False\n",
    "\n",
    "if in_kaggle():\n",
    "    c.settings.gpus = \"0\"\n",
    "\n",
    "    c.settings.dirs.working = \".\"\n",
    "    c.settings.dirs.input = \"../input/ubiquant-market-prediction/\"\n",
    "\n",
    "    pretraind_dir = \"../input/ump-models\"\n",
    "\n",
    "else:\n",
    "    c.settings.dirs.working = \"..\"\n",
    "    c.settings.dirs.input = \"../../inputs/\"\n",
    "\n",
    "    pretraind_dir = \"../../datasets/trainings\"\n",
    "\n",
    "pretrained = f\"\"\"\n",
    "- dir: {pretraind_dir}/2022-02-01_20-23-49/fold0/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-02-01_20-23-51/fold1/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-02-01_20-23-53/fold2/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-02-01_20-23-55/fold3/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-02-01_20-23-58/fold4/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-02-01_20-24-00/fold5/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-02-01_20-24-02/fold6/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-02-01_20-24-04/fold7/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-02-02_00-43-02/fold8/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-02-02_00-43-04/fold9/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-02-02_00-43-06/fold10/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-02-02_00-43-08/fold11/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-02-02_00-43-11/fold12/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-02-02_00-43-13/fold13/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-02-02_00-43-15/fold14/\n",
    "  model: ump_1\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "_pretrained = f\"\"\"\n",
    "- dir: {pretraind_dir}/2022-01-26_07-47-01/fold0/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-01-26_07-47-03/fold1/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-01-26_07-47-05/fold2/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-01-26_07-47-07/fold3/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-01-26_07-47-10/fold4/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-01-26_07-47-12/fold5/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-01-26_07-47-14/fold6/\n",
    "  model: ump_1\n",
    "\n",
    "- dir: {pretraind_dir}/2022-01-30_22-12-14/fold0/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-01-30_22-12-16/fold1/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-01-30_22-12-19/fold2/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-01-30_22-12-21/fold3/\n",
    "  model: ump_1\n",
    "- dir: {pretraind_dir}/2022-01-30_22-12-23/fold4/\n",
    "  model: ump_1\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "c.params.pretrained = OmegaConf.create(pretrained)\n",
    "\n",
    "print(OmegaConf.to_yaml(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import traceback\n",
    "\n",
    "import src.utils as utils\n",
    "import ubiquant\n",
    "from src.feature_store import Store\n",
    "from src.features.base import get_feature\n",
    "from src.make_feature import make_feature\n",
    "from src.make_model import load_model\n",
    "from src.run_loop import inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.fix_seed(c.params.seed)\n",
    "utils.debug_settings(c)\n",
    "device = utils.gpu_settings(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature set: ['f000']\n"
     ]
    }
   ],
   "source": [
    "feature_set = [\"f000\"]\n",
    "\n",
    "feature_set = list(sorted(list(set(feature_set))))\n",
    "print(f\"feature set: {feature_set}\")\n",
    "\n",
    "feature_func = [get_feature(f) for f in feature_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = Store.empty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = load_model(c, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ubiquant.make_env()  # initialize the environment\n",
    "iter_test = env.iter_test()  # an iterator which loops over the test set and sample submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n",
      "CPU times: user 5.74 s, sys: 18.2 s, total: 23.9 s\n",
      "Wall time: 22.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for test_df, sample_prediction_df in iter_test:\n",
    "    try:\n",
    "        gc.collect()\n",
    "\n",
    "        for row in test_df.values:\n",
    "            store.append(row)\n",
    "\n",
    "        pred_df = make_feature(test_df, store, feature_set, load_from_store=False, save_to_store=False, debug=True)\n",
    "        df = inference(c, pred_df, device, models)\n",
    "\n",
    "        # df = inference(c, test_df, device, models)\n",
    "\n",
    "        sample_prediction_df[\"target\"] = df[\"target\"]  # make your predictions here\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"ERROR!!!\")\n",
    "        print(traceback.format_exc())\n",
    "        pass\n",
    "\n",
    "    env.predict(sample_prediction_df)  # register your predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37-all-in-one",
   "language": "python",
   "name": "py37-all-in-one"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
