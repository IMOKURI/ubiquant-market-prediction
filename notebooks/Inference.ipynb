{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "def in_kaggle():\n",
    "    return \"kaggle_web_client\" in sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "\n",
    "def init_logger():\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    handler1 = logging.StreamHandler(stream=sys.stdout)\n",
    "    handler1.setFormatter(logging.Formatter(\"%(asctime)s [%(levelname)s] [%(module)s] %(message)s\"))\n",
    "    # handler2 = logging.FileHandler(filename=\"train.log\")\n",
    "    # handler2.setFormatter(logging.Formatter(\"%(asctime)s [%(levelname)s] [%(module)s] %(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    # logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "log = init_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### INSERT SOURCE CODE HERE FOR SUBMISSION #####\n",
    "\n",
    "if in_kaggle():\n",
    "    sys.path.append(\"../input/nptyping\")\n",
    "    sys.path.append(\"../input/typish\")\n",
    "else:\n",
    "    sys.path.append(\"..\")\n",
    "    sys.path.append(\"../../inputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if in_kaggle():\n",
    "    !pip -qq install ../input/pytorchtabnet/pytorch_tabnet-3.1.1-py3-none-any.whl\n",
    "    \n",
    "    # https://www.kaggle.com/speeddemon/install-hydra-offline-from-dataset\n",
    "\n",
    "    !cp -r /kaggle/input/hydracore105 /kaggle/working\n",
    "    !mv /kaggle/working/hydracore105/antlr4-python3-runtime-4.8.tar.gz.tmp /kaggle/working/hydracore105/antlr4-python3-runtime-4.8.tar.gz\n",
    "    !ls /kaggle/working/hydracore105\n",
    "\n",
    "    !pip install -qq /kaggle/working/hydracore105/* --ignore-installed PyYAML\n",
    "    \n",
    "    sys.path.append(\"../input/omegaconf/omegaconf-master\")\n",
    "    omega_conf_path = \"config/main.yaml\"\n",
    "    \n",
    "else:\n",
    "    omega_conf_path = \"../config/main.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "c = OmegaConf.load(omega_conf_path)\n",
    "\n",
    "c.settings.debug = False\n",
    "c.wandb.enabled = False\n",
    "\n",
    "if in_kaggle():\n",
    "    c.settings.gpus = \"0\"\n",
    "\n",
    "    c.settings.dirs.working = \".\"\n",
    "    c.settings.dirs.input = \"../input/ubiquant-market-prediction/\"\n",
    "    c.settings.dirs.feature = \"../input/ubiquant-parquet/\"\n",
    "\n",
    "    pretraind_dir = \"../input/ump-models\"\n",
    "\n",
    "else:\n",
    "    c.settings.dirs.working = \"..\"\n",
    "    c.settings.dirs.input = \"../../inputs/\"\n",
    "\n",
    "    pretraind_dir = \"../../datasets/trainings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = f\"\"\"\n",
    "- dir: {pretraind_dir}/2022-02-12_20-21-03/fold0/\n",
    "  model: ump_1dcnn\n",
    "- dir: {pretraind_dir}/2022-02-12_20-21-05/fold1/\n",
    "  model: ump_1dcnn\n",
    "- dir: {pretraind_dir}/2022-02-12_20-21-07/fold2/\n",
    "  model: ump_1dcnn\n",
    "- dir: {pretraind_dir}/2022-02-12_20-21-09/fold3/\n",
    "  model: ump_1dcnn\n",
    "- dir: {pretraind_dir}/2022-02-12_20-21-12/fold4/\n",
    "  model: ump_1dcnn\n",
    "- dir: {pretraind_dir}/2022-02-12_20-21-16/fold6/\n",
    "  model: ump_1dcnn\n",
    "- dir: {pretraind_dir}/2022-02-12_20-21-19/fold7/\n",
    "  model: ump_1dcnn\n",
    "- dir: {pretraind_dir}/2022-02-13_07-33-10/fold8/\n",
    "  model: ump_1dcnn\n",
    "- dir: {pretraind_dir}/2022-02-13_07-33-13/fold9/\n",
    "  model: ump_1dcnn\n",
    "- dir: {pretraind_dir}/2022-02-13_07-33-15/fold10/\n",
    "  model: ump_1dcnn\n",
    "- dir: {pretraind_dir}/2022-02-13_07-33-17/fold11/\n",
    "  model: ump_1dcnn\n",
    "- dir: {pretraind_dir}/2022-02-13_07-33-19/fold12/\n",
    "  model: ump_1dcnn\n",
    "- dir: {pretraind_dir}/2022-02-13_07-33-21/fold13/\n",
    "  model: ump_1dcnn\n",
    "- dir: {pretraind_dir}/2022-02-13_07-33-24/fold14/\n",
    "  model: ump_1dcnn\n",
    "- dir: {pretraind_dir}/2022-02-13_07-34-20/fold5/\n",
    "  model: ump_1dcnn\n",
    "\"\"\"\n",
    "\n",
    "pretrained_lgb = f\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "_pretrained = f\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "c.params.pretrained = OmegaConf.create(pretrained)\n",
    "c.params.pretrained_lgb = OmegaConf.create(pretrained_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-13 20:23:26,832 [INFO] [3244290467] defaults:\n",
      "- _self_\n",
      "hydra:\n",
      "  run:\n",
      "    dir: ../outputs/${now:%Y-%m-%d_%H-%M-%S}\n",
      "  job_logging:\n",
      "    formatters:\n",
      "      simple:\n",
      "        format: '%(asctime)s [%(levelname)s][%(module)s] %(message)s'\n",
      "wandb:\n",
      "  enabled: false\n",
      "  entity: imokuri\n",
      "  project: ump\n",
      "  dir: ${hydra:runtime.cwd}/../cache\n",
      "  group: default\n",
      "settings:\n",
      "  print_freq: 100\n",
      "  gpus: 6,7\n",
      "  dirs:\n",
      "    working: ..\n",
      "    input: ../../inputs/\n",
      "    feature: ${settings.dirs.input}features/\n",
      "    preprocess: ${settings.dirs.input}preprocess/\n",
      "  inputs:\n",
      "  - train.csv\n",
      "  - example_test.csv\n",
      "  - example_sample_submission.csv\n",
      "  debug: false\n",
      "  n_debug_data: 100000\n",
      "  amp: true\n",
      "  multi_gpu: true\n",
      "  training_method: nn\n",
      "params:\n",
      "  seed: 440\n",
      "  n_class: 1\n",
      "  preprocess: []\n",
      "  n_fold: 5\n",
      "  skip_training: false\n",
      "  epoch: 20\n",
      "  es_patience: 0\n",
      "  batch_size: 640\n",
      "  gradient_acc_step: 1\n",
      "  max_grad_norm: 1000\n",
      "  fold: combinational_purged\n",
      "  group_name: investment_id\n",
      "  time_name: time_id\n",
      "  label_name: target\n",
      "  use_feature: true\n",
      "  feature_set:\n",
      "  - f000\n",
      "  - f100\n",
      "  - f200\n",
      "  - f901\n",
      "  dataset: ump_1\n",
      "  model: ump_1dcnn\n",
      "  model_input: 901\n",
      "  model_window: 10\n",
      "  pretrained:\n",
      "  - dir: ../../datasets/trainings/2022-02-12_20-21-03/fold0/\n",
      "    model: ump_1dcnn\n",
      "  - dir: ../../datasets/trainings/2022-02-12_20-21-05/fold1/\n",
      "    model: ump_1dcnn\n",
      "  - dir: ../../datasets/trainings/2022-02-12_20-21-07/fold2/\n",
      "    model: ump_1dcnn\n",
      "  - dir: ../../datasets/trainings/2022-02-12_20-21-09/fold3/\n",
      "    model: ump_1dcnn\n",
      "  - dir: ../../datasets/trainings/2022-02-12_20-21-12/fold4/\n",
      "    model: ump_1dcnn\n",
      "  - dir: ../../datasets/trainings/2022-02-12_20-21-16/fold6/\n",
      "    model: ump_1dcnn\n",
      "  - dir: ../../datasets/trainings/2022-02-12_20-21-19/fold7/\n",
      "    model: ump_1dcnn\n",
      "  - dir: ../../datasets/trainings/2022-02-13_07-33-10/fold8/\n",
      "    model: ump_1dcnn\n",
      "  - dir: ../../datasets/trainings/2022-02-13_07-33-13/fold9/\n",
      "    model: ump_1dcnn\n",
      "  - dir: ../../datasets/trainings/2022-02-13_07-33-15/fold10/\n",
      "    model: ump_1dcnn\n",
      "  - dir: ../../datasets/trainings/2022-02-13_07-33-17/fold11/\n",
      "    model: ump_1dcnn\n",
      "  - dir: ../../datasets/trainings/2022-02-13_07-33-19/fold12/\n",
      "    model: ump_1dcnn\n",
      "  - dir: ../../datasets/trainings/2022-02-13_07-33-21/fold13/\n",
      "    model: ump_1dcnn\n",
      "  - dir: ../../datasets/trainings/2022-02-13_07-33-24/fold14/\n",
      "    model: ump_1dcnn\n",
      "  - dir: ../../datasets/trainings/2022-02-13_07-34-20/fold5/\n",
      "    model: ump_1dcnn\n",
      "  criterion: RMSELoss\n",
      "  optimizer: Adam\n",
      "  scheduler: CosineAnnealingWarmupRestarts\n",
      "  lr: 0.001\n",
      "  min_lr: 1.0e-06\n",
      "  weight_decay: 1.0e-05\n",
      "  label_smoothing: 1.0e-06\n",
      "  scoring: pearson\n",
      "  pretrained_lgb: {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log.info(OmegaConf.to_yaml(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import traceback\n",
    "\n",
    "import numpy as np\n",
    "import src.utils as utils\n",
    "import ubiquant\n",
    "from src.feature_store import Store\n",
    "from src.features.base import get_feature\n",
    "from src.make_feature import make_feature\n",
    "from src.make_model import load_model\n",
    "from src.run_loop import inference, inference_lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.fix_seed(c.params.seed)\n",
    "utils.debug_settings(c)\n",
    "device = utils.gpu_settings(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-13 20:23:28,505 [INFO] [3125860516] feature set: ['f000', 'f100', 'f200', 'f901']\n"
     ]
    }
   ],
   "source": [
    "feature_set = [\"f000\", \"f100\", \"f200\", \"f901\"]\n",
    "\n",
    "feature_set = list(sorted(list(set(feature_set))))\n",
    "log.info(f\"feature set: {feature_set}\")\n",
    "\n",
    "feature_func = [get_feature(f) for f in feature_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = Store.empty()\n",
    "# store = Store.train(c)  # Your notebook tried to allocate more memory than is available.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = load_model(c, device)\n",
    "models_lgb = load_model(c, device, c.params.pretrained_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ubiquant.make_env()  # initialize the environment\n",
    "iter_test = env.iter_test()  # an iterator which loops over the test set and sample submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_cols = [f\"f_{n}\" for n in range(300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n",
      "2022-02-13 20:23:40,524 [INFO] [<timed exec>] predictions size: (2, 15)\n",
      "2022-02-13 20:23:45,720 [INFO] [<timed exec>] predictions size: (3, 15)\n",
      "2022-02-13 20:23:50,903 [INFO] [<timed exec>] predictions size: (3, 15)\n",
      "2022-02-13 20:23:56,121 [INFO] [<timed exec>] predictions size: (1, 15)\n",
      "CPU times: user 5.15 s, sys: 18.6 s, total: 23.7 s\n",
      "Wall time: 23.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for test_df, sample_prediction_df in iter_test:\n",
    "    gc.collect()\n",
    "\n",
    "    # log.info(test_df[\"investment_id\"].dtype)  # int16\n",
    "    # log.info(test_df[feature_cols].values.dtype)  # float64\n",
    "\n",
    "    predictions_ = []\n",
    "\n",
    "    try:\n",
    "        # assert len(test_df[\"investment_id\"].unique()) == len(test_df[\"investment_id\"]), \"investment_id is not unique.\"\n",
    "\n",
    "        if c.params.use_feature:\n",
    "            for row in test_df.values:\n",
    "                # investment_id_ = int(row[1])\n",
    "                # features_ = row[2:302].astype(np.float32)\n",
    "\n",
    "                # log.info(f\"investment_id: {investment_id_}({type(investment_id_)}), features: {len(features_)}({features_.dtype})\")\n",
    "                store.append(row)\n",
    "\n",
    "                # log.info(f\"store: {store.investments[investment_id_].features.last_n(1).squeeze().shape}, input: {features_.shape}\")\n",
    "                # assert np.array_equal(\n",
    "                #     store.investments[investment_id_].features.last_n(1).squeeze(), features_\n",
    "                # ), \"Features are different before and after storing in the store\"\n",
    "\n",
    "            pred_df = make_feature(\n",
    "                test_df,\n",
    "                store,\n",
    "                feature_set,\n",
    "                load_from_store=False,\n",
    "                save_to_store=False,\n",
    "                debug=c.settings.debug,\n",
    "            )\n",
    "\n",
    "            # assert len(test_df) == len(pred_df), \"test_df and pred_df do not same size.\"\n",
    "            # assert list(pred_df.columns) == feature_cols, \"pred_df has feature_cols columns.\"\n",
    "            # assert np.array_equal(\n",
    "            #     test_df[feature_cols].astype(\"float32\").values, pred_df.values\n",
    "            # ), \"Default features do not match between test_df and pred_df.\"\n",
    "\n",
    "            if c.params.pretrained:\n",
    "                preds = inference(c, pred_df, device, models)\n",
    "                predictions_.append(preds)\n",
    "\n",
    "            if c.params.pretrained_lgb:\n",
    "                preds_lgb = inference_lightgbm(pred_df, models_lgb)\n",
    "                predictions_.append(preds_lgb)\n",
    "\n",
    "        else:\n",
    "            if c.params.pretrained:\n",
    "                preds_ = inference(c, test_df, device, models)\n",
    "                predictions_.append(preds_)\n",
    "\n",
    "            if c.params.pretrained_lgb:\n",
    "                preds_lgb_ = inference_lightgbm(test_df, models_lgb)\n",
    "                predictions_.append(preds_lgb_)\n",
    "\n",
    "        # assert np.array_equal(preds_, preds), \"Predictions do not match between test_df and pred_df.\"\n",
    "        # assert np.array_equal(preds_lgb_, preds_lgb), \"LightGBM predictions do not match between test_df and pred_df.\"\n",
    "\n",
    "        predictions = np.hstack(predictions_)\n",
    "        # predictions = np.hstack([preds_, preds_lgb_])\n",
    "        log.info(f\"predictions size: {predictions.shape}\")\n",
    "\n",
    "        sample_prediction_df[\"target\"] = np.nanmean(predictions, axis=1)\n",
    "\n",
    "        # sample_prediction_df.fillna({\"target\": 0}, inplace=True)\n",
    "\n",
    "        if c.params.use_feature:\n",
    "            for row in sample_prediction_df[[\"row_id\", \"target\"]].values:\n",
    "                store.append_post(row)\n",
    "\n",
    "    except Exception as e:\n",
    "        log.warning(traceback.format_exc())\n",
    "        raise\n",
    "\n",
    "    env.predict(sample_prediction_df)  # register your predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37-all-in-one",
   "language": "python",
   "name": "py37-all-in-one"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
