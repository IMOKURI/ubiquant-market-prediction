{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b02d0fe-17b6-4a30-9445-bc035af17743",
   "metadata": {},
   "source": [
    "# PoC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0b3f4d1-ea25-4fbf-a513-3c775fb5a1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../../inputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc1c3027-9a46-4388-9fd5-07d4b3ba83df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f35bb72f-a032-4e84-8a94-cf0d3501927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    # filename=__file__.replace('.py', '.log'),\n",
    "    stream=sys.stdout,\n",
    "    level=logging.getLevelName(\"INFO\"),\n",
    "    format=\"%(asctime)s [%(levelname)s] [%(module)s] %(message)s\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5210d1b-4683-4387-9e3e-716894134cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88dc8375-5484-43ff-9228-33906d9420c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebf72915-7219-45e7-bbc7-b2a66db453ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = OmegaConf.load(\"../config/main.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3478df2-66e3-497d-9a40-1fdb174e11a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.settings.debug = False\n",
    "c.wandb.enabled = False\n",
    "c.settings.dirs.working = \"..\"\n",
    "c.settings.dirs.input = \"../../inputs/\"\n",
    "c.settings.dirs.input_minimal = \"../../datasets/inputs/\"\n",
    "c.settings.dirs.preprocess = \"../../inputs/preprocess/\"\n",
    "\n",
    "c.settings.gpus = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e27e5544-eeab-428a-ab1c-eb8bf456a532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-26 22:47:43,104 [INFO] [3244290467] defaults:\n",
      "- _self_\n",
      "hydra:\n",
      "  run:\n",
      "    dir: ../outputs/${now:%Y-%m-%d_%H-%M-%S}\n",
      "  job_logging:\n",
      "    formatters:\n",
      "      simple:\n",
      "        format: '%(asctime)s [%(levelname)s][%(module)s] %(message)s'\n",
      "wandb:\n",
      "  enabled: false\n",
      "  entity: imokuri\n",
      "  project: ump\n",
      "  dir: ${hydra:runtime.cwd}/../cache\n",
      "  group: default\n",
      "settings:\n",
      "  print_freq: 100\n",
      "  gpus: '1'\n",
      "  dirs:\n",
      "    working: ..\n",
      "    input: ../../inputs/\n",
      "    input_minimal: ../../datasets/inputs/\n",
      "    feature: ${settings.dirs.input}features/\n",
      "    preprocess: ../../inputs/preprocess/\n",
      "  inputs:\n",
      "  - train.csv\n",
      "  - example_test.csv\n",
      "  - example_sample_submission.csv\n",
      "  debug: false\n",
      "  n_debug_data: 100000\n",
      "  amp: true\n",
      "  multi_gpu: true\n",
      "  training_method: nn\n",
      "params:\n",
      "  seed: 440\n",
      "  n_class: 10\n",
      "  preprocess:\n",
      "  - remove_china_shock\n",
      "  pca_n_components: 50\n",
      "  n_fold: 5\n",
      "  skip_training: false\n",
      "  epoch: 10\n",
      "  es_patience: 0\n",
      "  batch_size: 640\n",
      "  gradient_acc_step: 1\n",
      "  max_grad_norm: 1000\n",
      "  fold: combinational_purged\n",
      "  group_name: investment_id\n",
      "  time_name: time_id\n",
      "  label_name: target\n",
      "  use_feature: true\n",
      "  feature_set:\n",
      "  - f001\n",
      "  - f410\n",
      "  - f411\n",
      "  - f902\n",
      "  dataset: ump_1\n",
      "  model: ump_lstm\n",
      "  model_input: 900\n",
      "  model_window: 10\n",
      "  pretrained: []\n",
      "  criterion: RMSELoss\n",
      "  optimizer: Adam\n",
      "  scheduler: CosineAnnealingWarmupRestarts\n",
      "  lr: 0.001\n",
      "  min_lr: 1.0e-06\n",
      "  weight_decay: 1.0e-05\n",
      "  label_smoothing: 1.0e-06\n",
      "  scoring: pearson\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log.info(OmegaConf.to_yaml(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d89b2156-0d7e-4af1-8e67-f92deaa8585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ac19050-2411-4a11-b908-f1e8ea23f223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78f062fa-daf4-42a6-b248-b715a31f23ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-26 22:47:44,423 [INFO] [utils] CUDA_VISIBLE_DEVICES: 1\n",
      "2022-02-26 22:47:44,484 [INFO] [utils] torch device: cuda, device count: 1\n"
     ]
    }
   ],
   "source": [
    "device = utils.gpu_settings(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65e2cd0-b228-46ef-896d-cf82e20e693a",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5e5469b-9229-4af6-a049-c4d4b09d1d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-26 22:47:44,779 [INFO] [loader] Loading faiss with AVX2 support.\n",
      "2022-02-26 22:47:44,886 [INFO] [loader] Successfully loaded faiss with AVX2 support.\n"
     ]
    }
   ],
   "source": [
    "from src.load_data import InputData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ab02525-1930-4d5f-b55e-b38c703ef153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-26 22:47:44,912 [INFO] [load_data] Load feather file. path: ../../inputs/train.f\n",
      "2022-02-26 22:48:16,674 [INFO] [utils] Mem. usage decreased to 307Mb: 49% reduction\n",
      "2022-02-26 22:48:16,705 [INFO] [load_data] Load feather file. path: ../../inputs/example_test.f\n",
      "2022-02-26 22:48:16,781 [INFO] [utils] Mem. usage decreased to 0.0Mb: 49% reduction\n",
      "2022-02-26 22:48:16,782 [INFO] [load_data] Load feather file. path: ../../inputs/example_sample_submission.f\n",
      "2022-02-26 22:48:16,788 [INFO] [utils] Mem. usage decreased to 0.0Mb: 34% reduction\n"
     ]
    }
   ],
   "source": [
    "input = InputData(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d4ad746-645e-41c7-b9d7-f0506018f4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>investment_id</th>\n",
       "      <th>target</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>...</th>\n",
       "      <th>f_292</th>\n",
       "      <th>f_293</th>\n",
       "      <th>f_294</th>\n",
       "      <th>f_295</th>\n",
       "      <th>f_296</th>\n",
       "      <th>f_297</th>\n",
       "      <th>f_298</th>\n",
       "      <th>f_299</th>\n",
       "      <th>group_fold</th>\n",
       "      <th>time_fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.635488e+06</td>\n",
       "      <td>2.635488e+06</td>\n",
       "      <td>2.635488e+06</td>\n",
       "      <td>2.635488e+06</td>\n",
       "      <td>2.635488e+06</td>\n",
       "      <td>2.635488e+06</td>\n",
       "      <td>2.635488e+06</td>\n",
       "      <td>2.635488e+06</td>\n",
       "      <td>2.635488e+06</td>\n",
       "      <td>2.635488e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>2.635488e+06</td>\n",
       "      <td>2.635488e+06</td>\n",
       "      <td>2.635488e+06</td>\n",
       "      <td>2.635488e+06</td>\n",
       "      <td>2.635488e+06</td>\n",
       "      <td>2.635488e+06</td>\n",
       "      <td>2.635488e+06</td>\n",
       "      <td>2.635488e+06</td>\n",
       "      <td>2.635488e+06</td>\n",
       "      <td>2.635488e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.103500e+02</td>\n",
       "      <td>1.885160e+03</td>\n",
       "      <td>-1.702157e-02</td>\n",
       "      <td>6.950274e-04</td>\n",
       "      <td>-8.909235e-03</td>\n",
       "      <td>6.209589e-03</td>\n",
       "      <td>-1.757490e-02</td>\n",
       "      <td>-3.142135e-03</td>\n",
       "      <td>-1.961225e-03</td>\n",
       "      <td>-3.933720e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.558229e-03</td>\n",
       "      <td>9.289950e-04</td>\n",
       "      <td>-2.182449e-03</td>\n",
       "      <td>-2.326412e-02</td>\n",
       "      <td>-1.609894e-03</td>\n",
       "      <td>-5.184209e-03</td>\n",
       "      <td>-4.299405e-03</td>\n",
       "      <td>-3.754060e-03</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.500000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.708622e+02</td>\n",
       "      <td>1.083865e+03</td>\n",
       "      <td>9.220569e-01</td>\n",
       "      <td>1.097723e+00</td>\n",
       "      <td>1.043660e+00</td>\n",
       "      <td>1.034713e+00</td>\n",
       "      <td>9.686490e-01</td>\n",
       "      <td>9.959193e-01</td>\n",
       "      <td>1.119593e+00</td>\n",
       "      <td>1.080068e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.083052e+00</td>\n",
       "      <td>1.123110e+00</td>\n",
       "      <td>1.164162e+00</td>\n",
       "      <td>9.673325e-01</td>\n",
       "      <td>1.158741e+00</td>\n",
       "      <td>1.126991e+00</td>\n",
       "      <td>1.063325e+00</td>\n",
       "      <td>1.013074e+00</td>\n",
       "      <td>1.414214e+00</td>\n",
       "      <td>1.686267e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-9.419646e+00</td>\n",
       "      <td>-1.765789e+01</td>\n",
       "      <td>-6.579473e+00</td>\n",
       "      <td>-8.644268e+00</td>\n",
       "      <td>-1.240608e+01</td>\n",
       "      <td>-4.000015e+00</td>\n",
       "      <td>-8.833704e+00</td>\n",
       "      <td>-6.384251e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.183732e+00</td>\n",
       "      <td>-2.399478e+01</td>\n",
       "      <td>-8.911345e+00</td>\n",
       "      <td>-9.348986e+00</td>\n",
       "      <td>-7.366648e+00</td>\n",
       "      <td>-7.579406e+00</td>\n",
       "      <td>-6.707284e+00</td>\n",
       "      <td>-1.028264e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.930000e+02</td>\n",
       "      <td>9.510000e+02</td>\n",
       "      <td>-4.822457e-01</td>\n",
       "      <td>-4.268636e-01</td>\n",
       "      <td>-6.918773e-01</td>\n",
       "      <td>-6.546747e-01</td>\n",
       "      <td>-4.543629e-01</td>\n",
       "      <td>-3.231966e-01</td>\n",
       "      <td>-7.110226e-01</td>\n",
       "      <td>-8.051575e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.049787e-01</td>\n",
       "      <td>-2.051390e-01</td>\n",
       "      <td>-9.585723e-01</td>\n",
       "      <td>-5.027200e-01</td>\n",
       "      <td>-9.759416e-01</td>\n",
       "      <td>-7.407039e-01</td>\n",
       "      <td>-8.141529e-01</td>\n",
       "      <td>-5.032123e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.970000e+02</td>\n",
       "      <td>1.881000e+03</td>\n",
       "      <td>-8.900590e-02</td>\n",
       "      <td>2.451799e-01</td>\n",
       "      <td>-4.580044e-02</td>\n",
       "      <td>7.742916e-02</td>\n",
       "      <td>-2.804235e-01</td>\n",
       "      <td>-1.807949e-01</td>\n",
       "      <td>-1.967342e-02</td>\n",
       "      <td>6.589857e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.043986e-01</td>\n",
       "      <td>2.393769e-01</td>\n",
       "      <td>2.033623e-01</td>\n",
       "      <td>-2.872780e-01</td>\n",
       "      <td>7.143374e-03</td>\n",
       "      <td>-1.648386e-01</td>\n",
       "      <td>3.606625e-02</td>\n",
       "      <td>-2.855791e-01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.500000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.016000e+03</td>\n",
       "      <td>2.830000e+03</td>\n",
       "      <td>3.534553e-01</td>\n",
       "      <td>6.788467e-01</td>\n",
       "      <td>6.313426e-01</td>\n",
       "      <td>6.642895e-01</td>\n",
       "      <td>7.873586e-02</td>\n",
       "      <td>2.538166e-02</td>\n",
       "      <td>6.906360e-01</td>\n",
       "      <td>8.086394e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>4.779136e-01</td>\n",
       "      <td>5.475935e-01</td>\n",
       "      <td>8.738781e-01</td>\n",
       "      <td>1.196992e-01</td>\n",
       "      <td>9.685071e-01</td>\n",
       "      <td>6.232187e-01</td>\n",
       "      <td>7.972904e-01</td>\n",
       "      <td>1.359206e-01</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.219000e+03</td>\n",
       "      <td>3.773000e+03</td>\n",
       "      <td>1.203861e+01</td>\n",
       "      <td>7.845261e+00</td>\n",
       "      <td>8.707207e+00</td>\n",
       "      <td>8.009340e+00</td>\n",
       "      <td>3.575379e+01</td>\n",
       "      <td>7.662866e+01</td>\n",
       "      <td>7.646200e+00</td>\n",
       "      <td>6.778142e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.231185e+01</td>\n",
       "      <td>6.587691e+00</td>\n",
       "      <td>6.978151e+00</td>\n",
       "      <td>6.140367e+01</td>\n",
       "      <td>7.679950e+00</td>\n",
       "      <td>1.241804e+01</td>\n",
       "      <td>7.003982e+00</td>\n",
       "      <td>4.337021e+01</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            time_id  investment_id        target           f_0           f_1  \\\n",
       "count  2.635488e+06   2.635488e+06  2.635488e+06  2.635488e+06  2.635488e+06   \n",
       "mean   7.103500e+02   1.885160e+03 -1.702157e-02  6.950274e-04 -8.909235e-03   \n",
       "std    3.708622e+02   1.083865e+03  9.220569e-01  1.097723e+00  1.043660e+00   \n",
       "min    0.000000e+00   0.000000e+00 -9.419646e+00 -1.765789e+01 -6.579473e+00   \n",
       "25%    2.930000e+02   9.510000e+02 -4.822457e-01 -4.268636e-01 -6.918773e-01   \n",
       "50%    7.970000e+02   1.881000e+03 -8.900590e-02  2.451799e-01 -4.580044e-02   \n",
       "75%    1.016000e+03   2.830000e+03  3.534553e-01  6.788467e-01  6.313426e-01   \n",
       "max    1.219000e+03   3.773000e+03  1.203861e+01  7.845261e+00  8.707207e+00   \n",
       "\n",
       "                f_2           f_3           f_4           f_5           f_6  \\\n",
       "count  2.635488e+06  2.635488e+06  2.635488e+06  2.635488e+06  2.635488e+06   \n",
       "mean   6.209589e-03 -1.757490e-02 -3.142135e-03 -1.961225e-03 -3.933720e-04   \n",
       "std    1.034713e+00  9.686490e-01  9.959193e-01  1.119593e+00  1.080068e+00   \n",
       "min   -8.644268e+00 -1.240608e+01 -4.000015e+00 -8.833704e+00 -6.384251e+00   \n",
       "25%   -6.546747e-01 -4.543629e-01 -3.231966e-01 -7.110226e-01 -8.051575e-01   \n",
       "50%    7.742916e-02 -2.804235e-01 -1.807949e-01 -1.967342e-02  6.589857e-03   \n",
       "75%    6.642895e-01  7.873586e-02  2.538166e-02  6.906360e-01  8.086394e-01   \n",
       "max    8.009340e+00  3.575379e+01  7.662866e+01  7.646200e+00  6.778142e+00   \n",
       "\n",
       "       ...         f_292         f_293         f_294         f_295  \\\n",
       "count  ...  2.635488e+06  2.635488e+06  2.635488e+06  2.635488e+06   \n",
       "mean   ... -6.558229e-03  9.289950e-04 -2.182449e-03 -2.326412e-02   \n",
       "std    ...  1.083052e+00  1.123110e+00  1.164162e+00  9.673325e-01   \n",
       "min    ... -8.183732e+00 -2.399478e+01 -8.911345e+00 -9.348986e+00   \n",
       "25%    ... -7.049787e-01 -2.051390e-01 -9.585723e-01 -5.027200e-01   \n",
       "50%    ... -2.043986e-01  2.393769e-01  2.033623e-01 -2.872780e-01   \n",
       "75%    ...  4.779136e-01  5.475935e-01  8.738781e-01  1.196992e-01   \n",
       "max    ...  2.231185e+01  6.587691e+00  6.978151e+00  6.140367e+01   \n",
       "\n",
       "              f_296         f_297         f_298         f_299    group_fold  \\\n",
       "count  2.635488e+06  2.635488e+06  2.635488e+06  2.635488e+06  2.635488e+06   \n",
       "mean  -1.609894e-03 -5.184209e-03 -4.299405e-03 -3.754060e-03  2.000000e+00   \n",
       "std    1.158741e+00  1.126991e+00  1.063325e+00  1.013074e+00  1.414214e+00   \n",
       "min   -7.366648e+00 -7.579406e+00 -6.707284e+00 -1.028264e+01  0.000000e+00   \n",
       "25%   -9.759416e-01 -7.407039e-01 -8.141529e-01 -5.032123e-01  1.000000e+00   \n",
       "50%    7.143374e-03 -1.648386e-01  3.606625e-02 -2.855791e-01  2.000000e+00   \n",
       "75%    9.685071e-01  6.232187e-01  7.972904e-01  1.359206e-01  3.000000e+00   \n",
       "max    7.679950e+00  1.241804e+01  7.003982e+00  4.337021e+01  4.000000e+00   \n",
       "\n",
       "          time_fold  \n",
       "count  2.635488e+06  \n",
       "mean   2.500000e+00  \n",
       "std    1.686267e+00  \n",
       "min    0.000000e+00  \n",
       "25%    1.000000e+00  \n",
       "50%    2.500000e+00  \n",
       "75%    4.000000e+00  \n",
       "max    5.000000e+00  \n",
       "\n",
       "[8 rows x 305 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9442d474-d04c-45ec-90d8-5d95e62e2d65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13aab07b-6b2c-44e3-89bd-3cdd852303ef",
   "metadata": {},
   "source": [
    "## Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6868a75d-ce76-4f0f-8852-f4e726b0effa",
   "metadata": {},
   "outputs": [],
   "source": [
    "input.train.fillna({\"time_fold\": c.params.n_fold}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4da8214-5d7d-452b-842c-52c51629c59b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>investment_id</th>\n",
       "      <th>target</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>...</th>\n",
       "      <th>f_292</th>\n",
       "      <th>f_293</th>\n",
       "      <th>f_294</th>\n",
       "      <th>f_295</th>\n",
       "      <th>f_296</th>\n",
       "      <th>f_297</th>\n",
       "      <th>f_298</th>\n",
       "      <th>f_299</th>\n",
       "      <th>group_fold</th>\n",
       "      <th>time_fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.300875</td>\n",
       "      <td>0.932573</td>\n",
       "      <td>0.113691</td>\n",
       "      <td>-0.402206</td>\n",
       "      <td>0.378386</td>\n",
       "      <td>-0.203938</td>\n",
       "      <td>-0.413469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200075</td>\n",
       "      <td>0.819155</td>\n",
       "      <td>0.941183</td>\n",
       "      <td>-0.086764</td>\n",
       "      <td>-1.087009</td>\n",
       "      <td>-1.044826</td>\n",
       "      <td>-0.287605</td>\n",
       "      <td>0.321566</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.231040</td>\n",
       "      <td>0.810802</td>\n",
       "      <td>-0.514115</td>\n",
       "      <td>0.742368</td>\n",
       "      <td>-0.616673</td>\n",
       "      <td>-0.194255</td>\n",
       "      <td>1.771210</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.734579</td>\n",
       "      <td>0.819155</td>\n",
       "      <td>0.941183</td>\n",
       "      <td>-0.387617</td>\n",
       "      <td>-1.087009</td>\n",
       "      <td>-0.929529</td>\n",
       "      <td>-0.974060</td>\n",
       "      <td>-0.343624</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.568807</td>\n",
       "      <td>0.393974</td>\n",
       "      <td>0.615937</td>\n",
       "      <td>0.567806</td>\n",
       "      <td>-0.607963</td>\n",
       "      <td>0.068883</td>\n",
       "      <td>-1.083155</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.551904</td>\n",
       "      <td>-1.220772</td>\n",
       "      <td>-1.060166</td>\n",
       "      <td>-0.219097</td>\n",
       "      <td>-1.087009</td>\n",
       "      <td>-0.612428</td>\n",
       "      <td>-0.113944</td>\n",
       "      <td>0.243608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>-1.064780</td>\n",
       "      <td>-2.343535</td>\n",
       "      <td>-0.011870</td>\n",
       "      <td>1.874606</td>\n",
       "      <td>-0.606346</td>\n",
       "      <td>-0.586827</td>\n",
       "      <td>-0.815737</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.266359</td>\n",
       "      <td>-1.220772</td>\n",
       "      <td>0.941183</td>\n",
       "      <td>-0.609113</td>\n",
       "      <td>0.104928</td>\n",
       "      <td>-0.783423</td>\n",
       "      <td>1.151730</td>\n",
       "      <td>-0.773309</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.531940</td>\n",
       "      <td>0.842057</td>\n",
       "      <td>-0.262993</td>\n",
       "      <td>2.330030</td>\n",
       "      <td>-0.583422</td>\n",
       "      <td>-0.618392</td>\n",
       "      <td>-0.742814</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.741355</td>\n",
       "      <td>-1.220772</td>\n",
       "      <td>0.941183</td>\n",
       "      <td>-0.588445</td>\n",
       "      <td>0.104928</td>\n",
       "      <td>0.753279</td>\n",
       "      <td>1.345611</td>\n",
       "      <td>-0.737624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2635483</th>\n",
       "      <td>1219_3768</td>\n",
       "      <td>1219</td>\n",
       "      <td>3768</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.093530</td>\n",
       "      <td>-0.720275</td>\n",
       "      <td>-0.345497</td>\n",
       "      <td>-0.438781</td>\n",
       "      <td>-0.166972</td>\n",
       "      <td>-0.437182</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.660579</td>\n",
       "      <td>0.875537</td>\n",
       "      <td>0.421628</td>\n",
       "      <td>-0.428097</td>\n",
       "      <td>-0.075548</td>\n",
       "      <td>-0.533092</td>\n",
       "      <td>-0.193732</td>\n",
       "      <td>-0.581394</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2635484</th>\n",
       "      <td>1219_3769</td>\n",
       "      <td>1219</td>\n",
       "      <td>3769</td>\n",
       "      <td>-0.223264</td>\n",
       "      <td>-1.344935</td>\n",
       "      <td>-0.199987</td>\n",
       "      <td>-0.107702</td>\n",
       "      <td>-0.454677</td>\n",
       "      <td>-0.221914</td>\n",
       "      <td>-0.141174</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.670493</td>\n",
       "      <td>0.875537</td>\n",
       "      <td>0.421628</td>\n",
       "      <td>-0.729949</td>\n",
       "      <td>-1.514277</td>\n",
       "      <td>0.013145</td>\n",
       "      <td>-0.890270</td>\n",
       "      <td>-0.589705</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2635485</th>\n",
       "      <td>1219_3770</td>\n",
       "      <td>1219</td>\n",
       "      <td>3770</td>\n",
       "      <td>-0.559415</td>\n",
       "      <td>0.979489</td>\n",
       "      <td>-1.110491</td>\n",
       "      <td>1.006980</td>\n",
       "      <td>-0.467307</td>\n",
       "      <td>-0.159549</td>\n",
       "      <td>1.355671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.820784</td>\n",
       "      <td>-1.142157</td>\n",
       "      <td>0.421628</td>\n",
       "      <td>-0.363329</td>\n",
       "      <td>1.363181</td>\n",
       "      <td>-0.079106</td>\n",
       "      <td>-1.580124</td>\n",
       "      <td>-0.297625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2635486</th>\n",
       "      <td>1219_3772</td>\n",
       "      <td>1219</td>\n",
       "      <td>3772</td>\n",
       "      <td>0.009599</td>\n",
       "      <td>-2.565332</td>\n",
       "      <td>0.320301</td>\n",
       "      <td>0.076600</td>\n",
       "      <td>1.380182</td>\n",
       "      <td>-0.155366</td>\n",
       "      <td>-0.689000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133074</td>\n",
       "      <td>-1.142157</td>\n",
       "      <td>0.421628</td>\n",
       "      <td>-0.375288</td>\n",
       "      <td>-1.514277</td>\n",
       "      <td>-0.973762</td>\n",
       "      <td>0.608647</td>\n",
       "      <td>-0.372040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2635487</th>\n",
       "      <td>1219_3773</td>\n",
       "      <td>1219</td>\n",
       "      <td>3773</td>\n",
       "      <td>1.212112</td>\n",
       "      <td>-0.089557</td>\n",
       "      <td>0.190229</td>\n",
       "      <td>-0.548256</td>\n",
       "      <td>0.151205</td>\n",
       "      <td>0.079773</td>\n",
       "      <td>0.447962</td>\n",
       "      <td>...</td>\n",
       "      <td>3.271590</td>\n",
       "      <td>0.875537</td>\n",
       "      <td>0.421628</td>\n",
       "      <td>-0.170709</td>\n",
       "      <td>1.363181</td>\n",
       "      <td>-0.563314</td>\n",
       "      <td>0.669586</td>\n",
       "      <td>0.456400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2635488 rows × 306 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_id  time_id  investment_id    target       f_0       f_1  \\\n",
       "0              0_1        0              1 -0.300875  0.932573  0.113691   \n",
       "1              0_2        0              2 -0.231040  0.810802 -0.514115   \n",
       "2              0_6        0              6  0.568807  0.393974  0.615937   \n",
       "3              0_7        0              7 -1.064780 -2.343535 -0.011870   \n",
       "4              0_8        0              8 -0.531940  0.842057 -0.262993   \n",
       "...            ...      ...            ...       ...       ...       ...   \n",
       "2635483  1219_3768     1219           3768  0.033600  0.093530 -0.720275   \n",
       "2635484  1219_3769     1219           3769 -0.223264 -1.344935 -0.199987   \n",
       "2635485  1219_3770     1219           3770 -0.559415  0.979489 -1.110491   \n",
       "2635486  1219_3772     1219           3772  0.009599 -2.565332  0.320301   \n",
       "2635487  1219_3773     1219           3773  1.212112 -0.089557  0.190229   \n",
       "\n",
       "              f_2       f_3       f_4       f_5  ...     f_292     f_293  \\\n",
       "0       -0.402206  0.378386 -0.203938 -0.413469  ...  0.200075  0.819155   \n",
       "1        0.742368 -0.616673 -0.194255  1.771210  ... -0.734579  0.819155   \n",
       "2        0.567806 -0.607963  0.068883 -1.083155  ... -0.551904 -1.220772   \n",
       "3        1.874606 -0.606346 -0.586827 -0.815737  ... -0.266359 -1.220772   \n",
       "4        2.330030 -0.583422 -0.618392 -0.742814  ... -0.741355 -1.220772   \n",
       "...           ...       ...       ...       ...  ...       ...       ...   \n",
       "2635483 -0.345497 -0.438781 -0.166972 -0.437182  ... -0.660579  0.875537   \n",
       "2635484 -0.107702 -0.454677 -0.221914 -0.141174  ... -0.670493  0.875537   \n",
       "2635485  1.006980 -0.467307 -0.159549  1.355671  ...  0.820784 -1.142157   \n",
       "2635486  0.076600  1.380182 -0.155366 -0.689000  ...  0.133074 -1.142157   \n",
       "2635487 -0.548256  0.151205  0.079773  0.447962  ...  3.271590  0.875537   \n",
       "\n",
       "            f_294     f_295     f_296     f_297     f_298     f_299  \\\n",
       "0        0.941183 -0.086764 -1.087009 -1.044826 -0.287605  0.321566   \n",
       "1        0.941183 -0.387617 -1.087009 -0.929529 -0.974060 -0.343624   \n",
       "2       -1.060166 -0.219097 -1.087009 -0.612428 -0.113944  0.243608   \n",
       "3        0.941183 -0.609113  0.104928 -0.783423  1.151730 -0.773309   \n",
       "4        0.941183 -0.588445  0.104928  0.753279  1.345611 -0.737624   \n",
       "...           ...       ...       ...       ...       ...       ...   \n",
       "2635483  0.421628 -0.428097 -0.075548 -0.533092 -0.193732 -0.581394   \n",
       "2635484  0.421628 -0.729949 -1.514277  0.013145 -0.890270 -0.589705   \n",
       "2635485  0.421628 -0.363329  1.363181 -0.079106 -1.580124 -0.297625   \n",
       "2635486  0.421628 -0.375288 -1.514277 -0.973762  0.608647 -0.372040   \n",
       "2635487  0.421628 -0.170709  1.363181 -0.563314  0.669586  0.456400   \n",
       "\n",
       "         group_fold  time_fold  \n",
       "0               4.0        0.0  \n",
       "1               2.0        0.0  \n",
       "2               0.0        0.0  \n",
       "3               2.0        0.0  \n",
       "4               0.0        0.0  \n",
       "...             ...        ...  \n",
       "2635483         3.0        5.0  \n",
       "2635484         3.0        5.0  \n",
       "2635485         1.0        5.0  \n",
       "2635486         0.0        5.0  \n",
       "2635487         0.0        5.0  \n",
       "\n",
       "[2635488 rows x 306 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "081e43f5-0c9d-4092-8679-7fb4df4ee365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    527098\n",
       "4.0    527098\n",
       "2.0    527098\n",
       "3.0    527097\n",
       "0.0    527097\n",
       "Name: group_fold, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.train[\"group_fold\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2849c98d-0b62-4666-b8f4-f57be0decdbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    439248\n",
       "5.0    439248\n",
       "4.0    439248\n",
       "3.0    439248\n",
       "2.0    439248\n",
       "0.0    439248\n",
       "Name: time_fold, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.train[\"time_fold\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2194489c-de5c-40e7-a9b6-c3c74759e7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "group_fold  time_fold\n",
       "1.0         0.0          89294\n",
       "2.0         2.0          88471\n",
       "3.0         1.0          88417\n",
       "1.0         1.0          88367\n",
       "4.0         0.0          88255\n",
       "            3.0          88254\n",
       "            5.0          88228\n",
       "2.0         4.0          88211\n",
       "3.0         4.0          88186\n",
       "2.0         3.0          88158\n",
       "3.0         3.0          88143\n",
       "0.0         5.0          88142\n",
       "            2.0          88079\n",
       "3.0         5.0          88041\n",
       "0.0         3.0          87807\n",
       "            0.0          87758\n",
       "1.0         2.0          87737\n",
       "0.0         4.0          87725\n",
       "            1.0          87586\n",
       "4.0         4.0          87583\n",
       "3.0         2.0          87583\n",
       "2.0         5.0          87566\n",
       "1.0         4.0          87543\n",
       "2.0         1.0          87478\n",
       "4.0         1.0          87400\n",
       "            2.0          87378\n",
       "1.0         5.0          87271\n",
       "2.0         0.0          87214\n",
       "1.0         3.0          86886\n",
       "3.0         0.0          86727\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.train[[\"group_fold\", \"time_fold\"]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a94e738-a3e1-4175-b04f-0e3d9f6085ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.make_fold import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89ad596c-8b29-46ac-8d7c-615b831f5160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-26 22:48:40,474 [INFO] [make_fold] Num of training data: 1753256, num of validation data: 878496\n"
     ]
    }
   ],
   "source": [
    "train_folds, valid_folds = train_test_split(c, input.train, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4b78bfc-5578-4492-a4f4-08989e13196e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1753256"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d0bb58e-b402-4281-aa7a-b19df5c7b14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "878496"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972c4554-94b4-4316-98ed-604f9e592b9a",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ccb5abc9-b37b-40be-b8a6-0e757cba8f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.make_model import make_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15f09b4b-e38a-4907-b6b9-07de57e3e4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.params.model = \"ump_transformer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0eaff286-5a4d-4e05-bd48-caf17f48d57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model(c, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc67b7ea-a0a7-400a-879e-f38f1c03a829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): TransformerModel(\n",
       "    (bn_1): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (transformer): Transformer(\n",
       "      (encoder): TransformerEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=900, out_features=900, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=900, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=900, bias=True)\n",
       "            (norm1): LayerNorm((900,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((900,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=900, out_features=900, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=900, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=900, bias=True)\n",
       "            (norm1): LayerNorm((900,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((900,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=900, out_features=900, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=900, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=900, bias=True)\n",
       "            (norm1): LayerNorm((900,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((900,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (3): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=900, out_features=900, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=900, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=900, bias=True)\n",
       "            (norm1): LayerNorm((900,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((900,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=900, out_features=900, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=900, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=900, bias=True)\n",
       "            (norm1): LayerNorm((900,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((900,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (5): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=900, out_features=900, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=900, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=900, bias=True)\n",
       "            (norm1): LayerNorm((900,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((900,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((900,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): TransformerDecoder(\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerDecoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=900, out_features=900, bias=True)\n",
       "            )\n",
       "            (multihead_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=900, out_features=900, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=900, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=900, bias=True)\n",
       "            (norm1): LayerNorm((900,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((900,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((900,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): TransformerDecoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=900, out_features=900, bias=True)\n",
       "            )\n",
       "            (multihead_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=900, out_features=900, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=900, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=900, bias=True)\n",
       "            (norm1): LayerNorm((900,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((900,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((900,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): TransformerDecoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=900, out_features=900, bias=True)\n",
       "            )\n",
       "            (multihead_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=900, out_features=900, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=900, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=900, bias=True)\n",
       "            (norm1): LayerNorm((900,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((900,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((900,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (3): TransformerDecoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=900, out_features=900, bias=True)\n",
       "            )\n",
       "            (multihead_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=900, out_features=900, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=900, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=900, bias=True)\n",
       "            (norm1): LayerNorm((900,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((900,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((900,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (4): TransformerDecoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=900, out_features=900, bias=True)\n",
       "            )\n",
       "            (multihead_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=900, out_features=900, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=900, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=900, bias=True)\n",
       "            (norm1): LayerNorm((900,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((900,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((900,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (5): TransformerDecoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=900, out_features=900, bias=True)\n",
       "            )\n",
       "            (multihead_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=900, out_features=900, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=900, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=900, bias=True)\n",
       "            (norm1): LayerNorm((900,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((900,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((900,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((900,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (head): Linear(in_features=900, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9db35f81-fc2d-4641-88fa-35c0409a92ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = torch.randn(c.params.batch_size, c.params.model_input * 10).to(device)\n",
    "# input_ = torch.randn(c.params.batch_size, c.params.model_window, c.params.model_input).to(device)\n",
    "\n",
    "# num_gpu = len(c.settings.gpus.split(\",\"))\n",
    "# hidden = torch.zeros(1, c.params.batch_size // num_gpu, 300).to(device)\n",
    "# cell = torch.zeros(1, c.params.batch_size // num_gpu, 300).to(device)\n",
    "# hidden_cell = (hidden, cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3c6ee7e-9d1f-4c7c-973a-bf9aaead9519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([640, 9000])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b06c11c0-d3aa-4388-87b5-9e0f0e432596",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model(input_)\n",
    "# res, hidden_cell = model(input_, hidden_cell)\n",
    "# res, hidden_cell = model(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6de18f3f-b29d-4bc8-bc04-32962075a18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([640])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83c2dce5-bb05-4a3d-b8d5-f2101bdc24ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.3245e-01,  2.9517e-01,  3.9746e-01,  8.9844e-01,  4.2017e-01,\n",
       "        -2.7390e-02, -6.1035e-02,  8.7207e-01,  7.3291e-01,  6.2523e-03,\n",
       "         4.0283e-01,  5.1416e-01, -6.4969e-06,  6.0791e-01, -7.1387e-01,\n",
       "         3.8727e-02, -9.8389e-02, -6.9214e-02,  8.3789e-01,  2.0496e-01,\n",
       "         1.0010e+00,  1.4221e-01, -7.4707e-02,  8.9783e-02, -4.2191e-03,\n",
       "         1.8713e-01, -1.9263e-01,  2.1887e-01, -7.3730e-02,  2.4158e-01,\n",
       "         5.0018e-02,  1.3100e-02, -1.7346e-01, -5.5756e-02,  1.1328e+00,\n",
       "         4.1479e-01,  7.0020e-01,  5.7892e-02, -1.6418e-01,  4.4653e-01,\n",
       "         1.2988e-01,  8.0713e-01,  3.8232e-01,  1.3733e-01,  5.9326e-01,\n",
       "         1.9531e-01,  1.1787e+00,  9.1650e-01,  4.9744e-02,  3.1885e-01,\n",
       "         4.1113e-01,  4.5728e-01,  1.0576e+00, -1.2659e-01,  7.9883e-01,\n",
       "         5.5811e-01, -1.1200e-01, -5.0488e-01,  2.2339e-01,  9.2407e-02,\n",
       "        -5.7568e-01,  8.2715e-01,  2.6245e-01, -2.9761e-01,  6.9189e-01,\n",
       "         1.2930e+00,  5.0684e-01,  1.1016e+00, -8.4839e-02, -2.3901e-01,\n",
       "         4.5288e-01,  7.9443e-01,  1.3599e-01,  9.0234e-01,  8.2617e-01,\n",
       "        -3.5362e-03,  1.0107e+00, -1.0211e-01, -9.9304e-02,  3.7451e-01,\n",
       "        -4.8950e-01,  4.6692e-02,  1.1748e+00,  6.0889e-01,  1.7749e-01,\n",
       "         6.0254e-01,  6.3330e-01,  4.4495e-02,  5.6006e-01,  2.5830e-01,\n",
       "         9.6533e-01,  8.5547e-01,  6.1719e-01,  3.5034e-01, -3.1006e-01,\n",
       "        -3.3936e-01, -9.0186e-01,  7.2070e-01,  9.1357e-01,  2.8442e-01,\n",
       "         8.1055e-01,  1.0244e+00,  1.0193e-01, -1.2683e-01,  2.9248e-01,\n",
       "         9.7559e-01,  1.5601e-01,  2.9443e-01,  2.8003e-01,  1.1774e-01,\n",
       "         7.3926e-01,  5.1562e-01, -2.9150e-01,  3.6157e-01,  4.1626e-01,\n",
       "         7.2852e-01,  1.1084e+00,  3.8623e-01,  8.8867e-01,  1.1318e+00,\n",
       "         1.2769e-01, -8.8577e-03,  3.8770e-01,  4.0820e-01, -2.2842e-02,\n",
       "         1.1700e-01,  4.2554e-01,  6.1218e-02,  3.6279e-01,  6.0254e-01,\n",
       "        -1.6199e-01, -2.3914e-01,  5.2881e-01,  8.1726e-02,  2.6025e-01,\n",
       "         4.1504e-01, -1.8860e-01,  2.1069e-01,  9.7754e-01,  7.3792e-02,\n",
       "        -9.5154e-02, -6.2695e-01,  7.2815e-02,  5.0635e-01, -3.8525e-01,\n",
       "         4.5508e-01,  3.4937e-01, -4.2908e-02,  3.0542e-01,  4.2529e-01,\n",
       "         2.5171e-01,  3.5498e-01,  2.5406e-03, -1.4099e-01,  4.9927e-01,\n",
       "        -1.6516e-01,  7.2510e-02,  1.2744e+00,  1.7120e-02,  5.2393e-01,\n",
       "        -1.6650e-01,  9.3213e-01,  3.1470e-01, -3.1470e-01,  3.2886e-01,\n",
       "         8.8721e-01,  1.0166e+00,  3.0713e-01, -5.6915e-02,  4.4385e-01,\n",
       "         9.0869e-01,  3.6743e-01,  4.2017e-01,  5.3174e-01,  1.0353e-02,\n",
       "         5.4590e-01,  1.4319e-01,  5.1666e-02,  2.8491e-01,  1.3416e-01,\n",
       "         6.4746e-01, -1.1689e+00,  5.1270e-01,  1.1328e+00, -8.7708e-02,\n",
       "        -3.4399e-01,  3.1006e-01, -3.2013e-02,  2.5830e-01,  7.5000e-01,\n",
       "         9.3408e-01,  4.1528e-01,  8.8037e-01,  1.6602e-01,  5.8252e-01,\n",
       "        -1.4404e-01,  2.4280e-01,  2.0105e-01,  9.5605e-01, -8.1177e-02,\n",
       "        -1.1462e-01, -6.9160e-03,  5.6494e-01, -2.5406e-02, -3.1519e-01,\n",
       "         5.9229e-01,  8.1104e-01,  4.6045e-01, -2.0309e-02,  1.4905e-01,\n",
       "        -1.1627e-01,  7.0654e-01,  3.4644e-01, -1.2524e-01,  4.1919e-01,\n",
       "         2.3718e-01, -2.5732e-01,  3.2397e-01,  7.0117e-01, -1.5454e-01,\n",
       "         4.9988e-02,  3.6987e-02,  1.5820e+00,  2.9395e-01,  3.3340e-03,\n",
       "         6.2012e-01, -2.6718e-02,  7.2559e-01,  2.6904e-01,  7.2266e-01,\n",
       "        -1.7078e-01,  3.8647e-01,  7.6221e-01, -3.0746e-03,  7.7979e-01,\n",
       "         1.0264e+00,  4.9414e-01,  6.5967e-01,  1.1969e-01, -2.0239e-01,\n",
       "        -3.1763e-01,  1.4541e+00,  3.2837e-01,  4.8438e-01,  4.2749e-01,\n",
       "         5.4883e-01,  6.8408e-01,  7.2070e-01,  5.8105e-01,  6.6504e-01,\n",
       "         3.2739e-01,  6.1963e-01, -4.1089e-01, -3.2275e-01,  1.6858e-01,\n",
       "         2.0642e-01,  1.8616e-02, -3.5376e-01,  1.1652e-01, -6.5041e-03,\n",
       "         4.4116e-01, -2.8101e-01, -6.9385e-01,  8.3594e-01,  1.8262e-01,\n",
       "         1.5173e-01,  5.7227e-01,  5.7568e-01, -1.4709e-01,  9.4580e-01,\n",
       "         7.6465e-01,  8.0566e-01,  1.6980e-01,  1.4233e-01,  7.0496e-02,\n",
       "         8.0371e-01,  1.3696e-01,  9.4092e-01,  5.9180e-01,  2.2424e-01,\n",
       "         6.2939e-01, -3.9917e-01,  6.8359e-02, -4.6240e-01,  4.5239e-01,\n",
       "         5.0391e-01,  2.1851e-01,  1.1484e+00,  4.1138e-01,  3.2715e-01,\n",
       "         6.3037e-01,  5.3467e-01,  1.4514e-01,  6.9922e-01,  7.1875e-01,\n",
       "         8.5596e-01,  8.1006e-01,  9.1113e-01,  5.3711e-01,  1.2871e+00,\n",
       "        -4.6265e-02,  1.3562e-01,  1.3174e+00,  4.0259e-01,  4.1382e-01,\n",
       "         4.0894e-01,  7.8027e-01,  6.5430e-01, -3.8428e-01,  8.1592e-01,\n",
       "         6.5186e-01,  6.3037e-01,  4.9194e-01,  9.9365e-01,  4.9780e-01,\n",
       "         4.6729e-01, -1.1969e-01,  1.0801e+00,  1.8286e-01,  1.2622e-01,\n",
       "         6.9629e-01,  1.6455e-01,  7.0801e-01,  2.5244e-01,  7.5586e-01,\n",
       "         2.4683e-01,  4.8248e-02, -6.4331e-02,  4.2212e-01,  1.0461e-01,\n",
       "         8.2520e-01,  8.7158e-01,  1.9946e-01,  1.0293e+00,  9.2139e-01,\n",
       "         4.8438e-01,  2.3938e-01, -3.2935e-01, -6.5137e-01,  3.7646e-01,\n",
       "         1.1841e-01,  5.4492e-01,  5.6396e-01, -1.6736e-01,  1.4221e-01,\n",
       "         4.8145e-01,  2.4182e-01,  2.8613e-01, -3.4690e-05,  8.7256e-01,\n",
       "         8.5938e-01,  5.5664e-01, -1.8005e-01,  9.5337e-02,  2.1399e-01,\n",
       "         5.4834e-01,  5.1709e-01,  4.8999e-01, -4.0234e-01,  6.7236e-01,\n",
       "        -2.4524e-01,  1.9641e-01,  2.5562e-01,  9.6191e-01, -6.5247e-02,\n",
       "         8.7305e-01,  1.0089e-01,  1.1768e-01,  3.8403e-01, -3.9185e-01,\n",
       "         7.5049e-01,  1.4709e-01,  6.6895e-01,  2.3059e-01,  6.3086e-01,\n",
       "        -2.4338e-02,  4.2505e-01,  5.6494e-01,  1.3867e-01,  2.2693e-01,\n",
       "         2.3767e-01,  2.2034e-01,  1.5430e-01, -1.7090e-01, -3.0054e-01,\n",
       "         3.6469e-02,  5.2197e-01,  8.4326e-01,  2.6831e-01, -1.2463e-01,\n",
       "         4.9609e-01,  2.6270e-01, -2.0142e-01,  3.3374e-01,  3.1372e-01,\n",
       "        -3.8794e-01,  2.8589e-01,  2.1167e-01,  4.1772e-01,  1.6125e-01,\n",
       "         6.0742e-01,  5.4102e-01, -5.5359e-02,  3.7750e-02, -6.2402e-01,\n",
       "         3.4082e-01,  3.9429e-01,  2.3315e-01,  4.7021e-01, -7.2571e-02,\n",
       "         7.6660e-01,  7.8857e-01,  5.1367e-01, -1.7188e-01,  7.9590e-01,\n",
       "         4.2090e-01,  4.3610e-02, -3.8330e-02,  1.6028e-01,  2.3877e-01,\n",
       "         2.3389e-01,  1.4807e-01,  7.0947e-01,  4.7388e-01,  1.8823e-01,\n",
       "         1.3342e-01,  6.5332e-01, -1.3513e-01,  5.5615e-01,  1.1582e+00,\n",
       "         5.6250e-01, -3.4576e-02,  3.7231e-01, -1.2140e-01, -5.5322e-01,\n",
       "         1.5979e-01,  6.9824e-01,  1.2878e-01,  7.9150e-01,  2.5073e-01,\n",
       "         5.7037e-02,  6.2549e-01,  6.2354e-01,  8.4375e-01,  5.0879e-01,\n",
       "         8.0273e-01,  6.1328e-01,  4.2847e-01, -1.4661e-01,  6.8164e-01,\n",
       "         6.0156e-01,  3.2886e-01,  9.1455e-01,  5.1465e-01,  3.8013e-01,\n",
       "         3.2495e-01,  6.6113e-01,  5.1709e-01,  8.8184e-01,  4.2627e-01,\n",
       "         3.8916e-01,  2.8589e-01,  4.6460e-01, -1.9455e-02,  5.6396e-01,\n",
       "        -6.7627e-01,  6.4258e-01,  3.3301e-01, -7.5439e-01,  1.1365e-01,\n",
       "         3.5059e-01, -7.7271e-02, -2.3584e-01,  2.7393e-01,  5.9082e-01,\n",
       "         2.3340e-01,  4.3506e-01,  8.9697e-01, -1.3208e-01,  8.2764e-02,\n",
       "         9.9805e-01,  3.9966e-01,  1.1074e+00,  1.8933e-01,  2.4805e-01,\n",
       "         6.3477e-01,  9.0039e-01,  5.6250e-01,  7.0508e-01,  3.7207e-01,\n",
       "         1.1914e-01,  4.8413e-01,  1.7273e-01,  2.9565e-01,  4.9292e-01,\n",
       "        -2.5464e-01,  6.0742e-01,  9.9854e-02, -3.7012e-01,  4.3823e-01,\n",
       "         3.7817e-01,  8.0957e-01,  3.8867e-01, -1.7480e-01, -5.8691e-01,\n",
       "         1.0479e+00,  5.5566e-01,  2.9688e-01, -1.1499e-01,  9.7412e-01,\n",
       "         5.4346e-01,  3.9136e-01,  3.4204e-01,  5.0684e-01,  4.0552e-01,\n",
       "        -6.2744e-01, -4.9225e-02, -7.9102e-01,  8.6475e-01, -5.2002e-02,\n",
       "         9.0088e-02, -2.0276e-01,  3.7036e-01,  5.9229e-01,  4.1650e-01,\n",
       "         4.3042e-01, -9.6497e-02, -1.1047e-01, -5.4736e-01,  6.6406e-01,\n",
       "         7.5439e-01,  1.4121e+00, -1.1151e-01,  3.7744e-01, -7.7477e-03,\n",
       "         6.9629e-01,  5.5762e-01,  3.6621e-02,  2.8955e-01,  2.5040e-02,\n",
       "         6.6748e-01,  3.6353e-01,  1.8384e-01,  1.5503e-01, -2.9248e-01,\n",
       "         2.1301e-01,  2.6465e-01,  7.3096e-01,  6.0645e-01,  2.4182e-01,\n",
       "         2.9077e-01,  6.7871e-01,  2.4133e-01, -4.0674e-01, -4.2065e-01,\n",
       "         1.5942e-01,  7.5977e-01, -2.6147e-01,  3.8818e-02,  2.3560e-01,\n",
       "         9.3213e-01,  1.0681e-01,  7.5098e-01, -3.1189e-02,  8.8428e-01,\n",
       "         2.4707e-01, -4.0967e-01,  6.9189e-01,  2.2491e-02,  4.3457e-01,\n",
       "        -4.0430e-01,  6.4111e-01,  4.5776e-01, -2.9639e-01,  6.3281e-01,\n",
       "        -2.7417e-01,  1.6663e-01,  6.4453e-01, -7.8308e-02,  5.5566e-01,\n",
       "         1.4868e-01,  8.0615e-01,  1.2607e+00,  2.0203e-01,  1.4463e+00,\n",
       "         8.3154e-01,  5.4443e-01, -7.1411e-02, -2.9199e-01,  7.5684e-01,\n",
       "         3.7305e-01,  2.8784e-01, -1.8494e-01,  6.4258e-01,  1.3281e+00,\n",
       "         8.4473e-01,  2.0007e-01, -2.8442e-01,  1.4783e-01, -8.5754e-03,\n",
       "         3.2251e-01,  5.4004e-01,  5.9601e-02, -2.4878e-01,  2.8778e-02,\n",
       "         3.3057e-01,  9.0283e-01,  6.5479e-01,  6.7285e-01,  6.7236e-01,\n",
       "         6.5918e-01,  7.1289e-01,  6.5918e-01,  5.4492e-01,  2.5317e-01,\n",
       "        -6.8359e-02,  7.6855e-01,  1.0498e+00, -5.5615e-01,  6.7627e-01,\n",
       "         6.9385e-01, -6.6299e-03,  2.3779e-01,  7.5928e-02,  7.7588e-01,\n",
       "         8.1543e-02,  1.3203e+00,  5.6592e-01,  2.4573e-01,  1.8066e-01,\n",
       "         7.4023e-01,  3.0347e-01,  2.8467e-01,  7.6709e-01, -5.4980e-01,\n",
       "         5.9961e-01, -2.2400e-01,  6.5039e-01,  1.9836e-01, -2.7466e-01],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76352e24-6645-465d-a20b-d8267418f71a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37-all-in-one",
   "language": "python",
   "name": "py37-all-in-one"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
